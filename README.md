### This is a natural language processing course-based project. The project is to designed an encoder-decoder with multiple attention mechanism to translate Chinese/Vietnamese to English


<pre>
 <b>Chinese_GRU.ipynb:</b> Includes GRU-based Luong attention/no attention model for Chinese corpus
</pre>




## Completed
:white_check_mark: Add dataloader

:white_check_mark: Train Unknown word representation

:white_check_mark: Mask

:white_check_mark: Minibatch

:white_check_mark: Bleu score

:white_check_mark: Save model

:white_check_mark: Self-attention

:white_check_mark: Multiple layers in encoder and decoder

:white_check_mark: Without Attention

:white_check_mark: LSTM

:white_check_mark: Bean Search

:white_check_mark: Play around the original data with respect to tokenization


## Future Work
* Ipynb to py

* Transformers


