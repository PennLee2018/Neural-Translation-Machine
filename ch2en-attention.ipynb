{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jieba\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/46/c6f9179f73b818d5827202ad1c4a94e371a29473b7f043b736b4dab6b8cd/jieba-0.39.zip (7.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.3MB 1.5MB/s ta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: jieba\n",
      "  Running setup.py bdist_wheel for jieba ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/nansu/Library/Caches/pip/wheels/c9/c7/63/a9ec0322ccc7c365fd51e475942a82395807186e94f0522243\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.39\n"
     ]
    }
   ],
   "source": [
    "!pip3 install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\n",
      "  Downloading https://files.pythonhosted.org/packages/37/51/bffea2b666d59d77be0413d35220022040a1f308c39009e5b023bc4eb8ab/sacrebleu-1.2.12.tar.gz\n",
      "Collecting typing (from sacrebleu)\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/bd/eee1157fc2d8514970b345d69cb9975dcd1e42cd7e61146ed841f6e68309/typing-3.6.6-py3-none-any.whl\n",
      "Building wheels for collected packages: sacrebleu\n",
      "  Running setup.py bdist_wheel for sacrebleu ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/sunan/Library/Caches/pip/wheels/ea/0a/7d/ddcbdcd15a04b72de1b3f78e7e754aab415aff81c423376385\n",
      "Successfully built sacrebleu\n",
      "\u001b[31mdistributed 1.16.3 requires msgpack-python, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow-tensorboard 0.1.8 has requirement bleach==1.5.0, but you'll have bleach 2.1.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow-tensorboard 0.1.8 has requirement html5lib==0.9999999, but you'll have html5lib 1.0.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: typing, sacrebleu\n",
      "Successfully installed sacrebleu-1.2.12 typing-3.6.6\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python preprocess_translation/token_zh_en.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import operator\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import sacrebleu\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "vocab_size = 60000\n",
    "hidden_size = 256\n",
    "# emb_size = 256\n",
    "MAX_LENGTH = 100 # since 99% source sentence is <= 100\n",
    "# MAX_LENGTH_1 = max(len(pair[0].split(\" \")) for pair in pairs)\n",
    "# MAX_LENGTH_2 = max(len(pair[1].split(\" \")) for pair in pairs)\n",
    "dropout_p = 0.1\n",
    "teacher_forcing_ratio = 0.5\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = open('iwslt-zh-en/train.tok.zh').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['深海 中 的 生命 － 大卫 . 盖罗 ',\n",
       " '大卫 . 盖罗 通过 潜水艇 拍下 的 影片 把 我们 带到 了 地球 最 黑暗 ， 最 险恶 同时 也 最 美丽 的 生物 栖息地 。 这里 是 海洋 深处 的 峡谷 和 火山 脊 ， 这里 怪诞 ， 适应力 强 而且 数量 惊人 的 生命 。 ',\n",
       " '大卫 . 盖罗 ： 这位 是 比尔 . 兰格 ，   我 是 大卫 . 盖罗 。 ',\n",
       " '我们 将 用 一些 影片 来 讲述 一些 深海 里 的 故事 。 ',\n",
       " '我们 这有 不少 精彩 的 泰坦尼克 的 影片 ，   可惜 您 今天 看不到 。 ',\n",
       " '泰坦尼克号   是 拿 了 不少 票房 冠军   但 事实上 它 并 不是 关于 海洋 的 最 刺激 的 故事 。 ',\n",
       " '原因 在于 我们 一直 没 把 海洋 当 回事儿 。 ',\n",
       " '大家 想想 ， 海洋 占 了 地球 面积 的 75 ％ 。 ',\n",
       " '地球 的 大部分 都 是 海水 。 ',\n",
       " '海洋 的 平均 深度 是 两英里 ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = open('iwslt-zh-en/train.tok.en').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Life in the deep oceans',\n",
       " 'With vibrant video clips captured by submarines , David Gallo takes us to some of Earth &apos;s darkest , most violent , toxic and beautiful habitats , the valleys and volcanic ridges of the oceans &apos; depths , where life is bizarre , resilient and shockingly abundant .',\n",
       " 'This is Bill Lange . I &apos;m Dave Gallo .',\n",
       " 'And we &apos;re going to tell you some stories from the sea here in video .',\n",
       " 'We &apos;ve got some of the most incredible video of Titanic that &apos;s ever been seen , and we &apos;re not going to show you any of it .',\n",
       " 'The truth of the matter is that the Titanic -- even though it &apos;s breaking all sorts of box office records -- it &apos;s not the most exciting story from the sea .',\n",
       " 'And the problem , I think , is that we take the ocean for granted .',\n",
       " 'When you think about it , the oceans are 75 percent of the planet .',\n",
       " 'Most of the planet is ocean water .',\n",
       " 'The average depth is about two miles .']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"EOS\", 2:\"EOS\", 3:\"UNK\"}\n",
    "        self.n_words = 4  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeEnString(s):\n",
    "#    s = unicodeToAscii(s.lower().strip())\n",
    "#    s = re.sub(r\"&apos;\", r\" \", s)\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "def normalizeChString(s):\n",
    "#    s = re.sub(r\"([。！？])\", r\" \\1\", s)\n",
    "#    s = re.sub(r\"[.-*]+\", r\" \", s)\n",
    "    return s.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It apos s very pretty and it has rapidly started to overgrow the once very rich biodiversity of the northwestern Mediterranean .'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizeEnString(\"It &apos;s very pretty , and it has rapidly started to overgrow the once very rich biodiversity of the northwestern Mediterranean .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, data='train'):\n",
    "    #data: train/dev/test\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    zh_lines = open('iwslt-zh-en/{}.tok.zh'.format(data)).read().split('\\n')\n",
    "    en_lines = open('iwslt-zh-en/{}.tok.en'.format(data)).read().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeChString(element[0]), normalizeEnString(element[1])] for element in zip(zh_lines, en_lines)]\n",
    "\n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "#    pairs = filterPairs(pairs)\n",
    "#    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 213378 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "ch 91144\n",
      "eng 59373\n",
      "Build vocabulary by top 60000 frequent word...\n",
      "ch 91144\n",
      "['他们 把 旧 的 卷帘门   扔进 垃圾 回收 处', 'They had thrown the old shutter in the garbage collection place .']\n"
     ]
    }
   ],
   "source": [
    "def build_topwordVocab(lang, vocab_size):\n",
    "    print(\"Build vocabulary by top {} frequent word...\".format(vocab_size))\n",
    "    sorted_word2Count = sorted(lang.word2count.items(),\n",
    "        key=operator.itemgetter(1),\n",
    "        reverse=True)\n",
    "    sorted_words = [x[0] for x in sorted_word2Count[:vocab_size]]\n",
    "    \n",
    "#    print(sorted_words)\n",
    "#    lang.index2word = {}\n",
    "    lang.index2word[0] = \"PAD\"\n",
    "    lang.index2word[1] = \"SOS\"\n",
    "    lang.index2word[2] = \"EOS\"\n",
    "    lang.index2word[3] = \"UNK\"\n",
    "    \n",
    "    for ind, word in enumerate(sorted_words):\n",
    "            lang.word2index[word] = ind + 4\n",
    "            \n",
    "\n",
    "#    lang.word2index = {}\n",
    "    for ind, word in enumerate(sorted_words):\n",
    "        lang.index2word[ind + 4] = word\n",
    "    \n",
    "    lang.n_words = len(lang.index2word)\n",
    "    \n",
    "    print(lang.name, lang.n_words)\n",
    "    return lang\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('ch', 'eng')\n",
    "\n",
    "input_lang = build_topwordVocab(input_lang,vocab_size)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build vocabulary by top 60000 frequent word...\n",
      "eng 59373\n"
     ]
    }
   ],
   "source": [
    "output_lang = build_topwordVocab(output_lang, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    }
   ],
   "source": [
    "_, _, val_pairs = readLangs('ch', 'eng', 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pairs = val_pairs[:-1] # since last line is '',''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['声音 颤动 ， 虚弱 ， 和 僵化', 'We see vocal tremor weakness and rigidity .']\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(val_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input = [normalizeChString(line) for line in open('iwslt-zh-en/dev.tok.zh').read().split('\\n')]\n",
    "val_output = [normalizeEnString(line) for line in open('iwslt-zh-en/dev.tok.en').read().split('\\n')]\n",
    "val_inputs = []\n",
    "val_outputs = []\n",
    "for element in zip(val_input, val_output):\n",
    "    val_inputs.append(element[0])\n",
    "    val_outputs.append(element[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_word2Count = sorted(output_lang.word2count.items(),\n",
    "    key=operator.itemgetter(1),\n",
    "    reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted_word2Count ###标点符号排第一 之后要改掉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    idxs = []\n",
    "    for word in sentence.split(' '):\n",
    "        try:\n",
    "            idxs.append(lang.word2index[word])\n",
    "        except KeyError:\n",
    "            idxs.append(3)  # 3 is the id of 'UNK'\n",
    "    idxs.append(EOS_token)\n",
    "    return idxs\n",
    "\n",
    "# def tensorFromSentence(lang, sentence):\n",
    "#     indexes = indexesFromSentence(lang, sentence)\n",
    "#     indexes.append(EOS_token)\n",
    "#     return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "# def tensorsFromPair(pair):\n",
    "#     input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "#     target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "#     return (input_tensor, target_tensor)\n",
    "\n",
    "class VocabDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "#         pairs = [tensorsFromPair(pair) for pair in pairs]\n",
    "#         self.source_sent_list = [i[0] for i in pairs]\n",
    "#         self.target_sent_list = [i[1] for i in pairs]\n",
    "        \n",
    "        self.source_sent_list = [indexesFromSentence(input_lang,pair[0]) for pair in pairs]\n",
    "        self.target_sent_list = [indexesFromSentence(output_lang,pair[1]) for pair in pairs]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.source_sent_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        token1_idx = self.source_sent_list[key][:MAX_LENGTH]\n",
    "        token2_idx = self.target_sent_list[key][:MAX_LENGTH]\n",
    "        return [token1_idx,token2_idx, len(token1_idx), len(token2_idx)]\n",
    "\n",
    "    \n",
    "def Vocab_collate_func(batch):\n",
    "    source_sent_list = []\n",
    "    target_sent_list = []\n",
    "    source_len_list = []\n",
    "    target_len_list = []\n",
    "\n",
    "    for datum in batch:   ### batch = sample\n",
    "        source_len_list.append(datum[2])\n",
    "        target_len_list.append(datum[3])\n",
    "\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        \n",
    "        # source sentence processing\n",
    "        padded_source = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_LENGTH-datum[2])),          ### 0代表左边没有pad,右边的值代表右边pad的个数\n",
    "                                mode=\"constant\", constant_values=PAD_token)\n",
    "        source_sent_list.append(padded_source)\n",
    "        \n",
    "        # target sentence processing\n",
    "        padded_target = np.pad(np.array(datum[1]), \n",
    "                                pad_width=((0,MAX_LENGTH-datum[3])),          ### 0代表左边没有pad,右边的值代表右边pad的个数\n",
    "                                mode=\"constant\", constant_values=PAD_token)\n",
    "        target_sent_list.append(padded_target)\n",
    "        \n",
    "    return [torch.tensor(source_sent_list,device = device), \n",
    "            torch.tensor(target_sent_list,device = device),\n",
    "            torch.LongTensor(source_len_list,device = device), \n",
    "            torch.LongTensor(target_len_list,device = device)]\n",
    "\n",
    "train_dataset = VocabDataset(pairs)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=Vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = VocabDataset(val_pairs)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        collate_fn=Vocab_collate_func,\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(inputs, outputs, len1, len2) in enumerate(train_loader):\n",
    "    a, b = outputs, len2\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   54,     6,    66,  ...,     0,     0,     0],\n",
       "        [    9, 11713,     2,  ...,     0,     0,     0],\n",
       "        [   16,   714,    36,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [   52,    65,     8,  ...,     0,     0,     0],\n",
       "        [   28,   582,  2715,  ...,     0,     0,     0],\n",
       "        [85073,    17,   527,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   54,     6,    66,    15,   453,     6,     8,     5,   448,    10,\n",
       "            6,    15, 81928,     5, 12774,     6,     4,     4,    20, 12056,\n",
       "           11,   585,  5338,   453,     7,     2,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, bidirectional=True)\n",
    "        self.linear = nn.Linear(2*hidden_size, hidden_size)\n",
    "    def forward(self, input, hidden, batch_size):\n",
    "        embedded = self.embedding(input).view(1, batch_size, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.linear(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(2, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs, batch_size):\n",
    "        embedded = self.embedding(input).view(1, batch_size, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "#         embedded: torch.Size([1, 32, 256])\n",
    "#         hidden: torch.Size([1, 32, 256])\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)   \n",
    "#         attn_weights:torch.Size([32, 100])\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1),\n",
    "                                 encoder_outputs.transpose(0,1))\n",
    "#         encoder_outputs: 100*32*256 attn_applied: 32*1*256\n",
    "        output = torch.cat((embedded[0], attn_applied.transpose(0,1)[0]), 1)\n",
    "\n",
    "        # output: 32*768\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        # output 1*32*256\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "#         output: torch.Size([32, 69126])\n",
    "#         hidden: torch.Size([1, 32, 256])\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just one sentence input, could be batchlized \n",
    "def train(input_tensor, target_tensor, encoder, decoder,\n",
    "          encoder_optimizer, decoder_optimizer, criterion, mask = None):\n",
    "    batch_size = input_tensor.size(1)\n",
    "    encoder_hidden = encoder.initHidden(batch_size)\n",
    "    encoder_optimizer.zero_grad()  # zero out the accumulated gradient over mini-batch\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0) # length of source sentence\n",
    "    target_length = target_tensor.size(0)\n",
    "    encoder_outputs = torch.zeros(target_length, batch_size, encoder.hidden_size, device=device) \n",
    "    # (seq_length, BATCH_SIZE,hidden_size*2) 2 due to bidirection\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "#    print(batch_size)\n",
    "    # feed-forward layer resulting encoder outputs, ei refers to each word token in input sentence\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden, batch_size)  \n",
    "        # encoder_output: torch.Size([1, 32, 512]) encoder_hidden: torch.Size([2, 32, 256])\n",
    "        encoder_outputs[ei] = encoder_output[0] \n",
    "    # change the shape of encoder output to fit into decoder \n",
    "    encoder_hidden = nn.Linear(2*hidden_size,hidden_size)(\n",
    "        torch.cat((encoder_hidden[0],encoder_hidden[1]),dim = 1)).unsqueeze(0)\n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]*batch_size], device=device)  # decoder_input: torch.Size([1, 32])\n",
    "    # init decoder hidden \n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs, batch_size)\n",
    "            \n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "            temp_loss = criterion(decoder_output, target_tensor[di])\n",
    "            loss += temp_loss * mask[di:di+1].float()  \n",
    "#            loss += temp_loss.float()\n",
    "            ave_loss = loss.sum()/batch_size \n",
    "            \n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            # decoder_input: torch.Size([1, 32])\n",
    "            # decoder_hidden: torch.Size([1, 32, 256]) 1 token * batch * hidden size\n",
    "            # encoder_outputs: torch.Size([100, 32, 512])\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs, batch_size)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            # topv: 32*1\n",
    "            # topi: 32*1\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            # decoder_input: 32\n",
    "            # target_tensor: 100*32\n",
    "            # decoder_output: 32*69127 \n",
    "            temp_loss = criterion(decoder_output, target_tensor[di])\n",
    "            loss += temp_loss * mask[di:di+1].float()\n",
    "#            loss += temp_loss.float()\n",
    "            # loss size 1*32\n",
    "            ave_loss = loss.sum()/batch_size  \n",
    "            \n",
    "    ave_loss.backward()\n",
    "    \n",
    "    \n",
    "    encoder_optimizer.step()   # update parameters\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return ave_loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=100, plot_every=100, learning_rate=0.005):\n",
    "    start = time.time()\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss(reduce = False) ##!!!!!!!!!!1 这个loss是否要换成crossentropy\n",
    "\n",
    "    for epoch in range(1, n_iters + 1):\n",
    "        plot_losses = []\n",
    "        print_loss_total = 0  # Reset every print_every\n",
    "        plot_loss_total = 0  # Reset every plot_every\n",
    "        for i, (input_sentences, target_sentences,len1,len2) in enumerate(train_loader): \n",
    "            input_tensor = input_sentences.transpose(0,1)   # 13*100 to 100*13\n",
    "            target_tensor = target_sentences.transpose(0,1)\n",
    "            mask = target_tensor.ge(1)   # 100 * 13\n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion, mask = mask)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if i > 0 and i % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                bleu_score, (sys_sents, ref_sents) = test_model(encoder, decoder, val_loader)\n",
    "                print('Time: {}, Epoch: [{}/{}], Step: [{}/{}], Train Loss: {}, Validation Score: {} \\n Predicted sentence: {} \\n Reference sentence: {}'.format(\n",
    "                    timeSince(start, i + 1/len(train_loader)), epoch, n_iters, i, \n",
    "                    len(train_loader),print_loss_avg, bleu_score, sys_sents, ref_sents))\n",
    "\n",
    "            if i > 0 and i % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "        print(plot_losses)\n",
    "        showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_outputs(encoder, decoder, input_sentences, max_length=MAX_LENGTH): \n",
    "    with torch.no_grad():\n",
    "        input_tensor = input_sentences.transpose(0,1)   # 32*100 to 100*32\n",
    "        batch_size = input_tensor.size(1)\n",
    "        encoder_hidden = encoder.initHidden(batch_size)\n",
    "\n",
    "        input_length = input_tensor.size(0) # length of source sentence\n",
    "        encoder_outputs = torch.zeros(max_length, batch_size, encoder.hidden_size, device=device) \n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], \n",
    "                                                     encoder_hidden, batch_size)  \n",
    "            encoder_outputs[ei] = encoder_output[0] \n",
    "            \n",
    "        encoder_hidden = nn.Linear(2*hidden_size,hidden_size)(\n",
    "            torch.cat((encoder_hidden[0],encoder_hidden[1]),dim = 1)).unsqueeze(0)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]*batch_size], device=device)  # decoder_input: torch.Size([1, 32])\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        decoded_words = np.empty((max_length, batch_size), dtype=object)\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs, batch_size)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "\n",
    "#            topi_lst = topi.squeeze().detach().tolist()\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            \n",
    "            decoded_words[di:] = np.array(['<EOS>' if idx==EOS_token else output_lang.index2word[idx] for idx in decoder_input.tolist()])\n",
    "        \n",
    "        return decoded_words.transpose()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(encoder, decoder, loader):\n",
    "    score = []\n",
    "    for i, (input_sentences, target_sentences, len1, len2) in enumerate(loader):\n",
    "        batch_size = input_sentences.size(0)\n",
    "#        print(batch_size)\n",
    "        sys_sentences = []\n",
    "        for sentence in get_batch_outputs(encoder, decoder, input_sentences):\n",
    "            try:\n",
    "                end_idx = sentence.tolist().index('<EOS>')\n",
    "                sys_sentences.append(' '.join(sentence[:end_idx]))\n",
    "            except ValueError:\n",
    "                sys_sentences.append(' '.join(sentence))\n",
    "#        sys_sentences = [' '.join(sentence) for sentence in get_batch_outputs(encoder, decoder, input_sentences)]\n",
    "        ref_sentences = [val_pair[1] for val_pair in val_pairs[i*batch_size:(i+1)*batch_size]]\n",
    "#        print(ref_sentences)\n",
    "        score_batch = [sacrebleu.corpus_bleu([sys],[[ref]]).score for sys, ref in zip(sys_sentences, ref_sentences)]\n",
    "        score.append(sum(score_batch)/len(score_batch))\n",
    "    return sum(score)/len(score), (sys_sentences[0], ref_sentences[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_model(encoder1,attn_decoder1, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluateRandomly(encoder, decoder, n=10):\n",
    "#     for i in range(n):\n",
    "#         pair = random.choice(pairs)\n",
    "#         print('>', pair[0])\n",
    "#         print('=', pair[1])\n",
    "#         output_words = generate_output(encoder, decoder, pairs)\n",
    "#         output_sentence = ' '.join(output_words)\n",
    "#         print('<', output_sentence)\n",
    "#         print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING AND EVALUATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunan/anaconda/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 11m 47s (- -12m 47s), Epoch: [1/3], Step: [20/6669], Train Loss: 1.673552219390869, Validation Score: 0.272699926481706 \n",
      " Predicted sentence: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      " Reference sentence: Thanks .\n"
     ]
    }
   ],
   "source": [
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.5).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 3, print_every=20,plot_every=1)\n",
    "\n",
    "torch.save(encoder1.state_dict(), \"saved_model/encoder_hiddenSize{}\".format(hidden_size))\n",
    "torch.save(attn_decoder1.state_dict(), \"saved_model/attn_decoder_hiddenSize{}\".format(hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
