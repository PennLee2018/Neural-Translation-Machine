{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python preprocess_translation/token_zh_en.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import operator\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import sacrebleu\n",
    "from masked_cross_entropy import *\n",
    "\n",
    "import random\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "vocab_size = 60000\n",
    "hidden_size = 256\n",
    "# emb_size = 256\n",
    "MAX_LENGTH = 100 # since 99% source sentence is <= 100\n",
    "# MAX_LENGTH_1 = max(len(pair[0].split(\" \")) for pair in pairs)\n",
    "# MAX_LENGTH_2 = max(len(pair[1].split(\" \")) for pair in pairs)\n",
    "dropout_p = 0.1\n",
    "teacher_forcing_ratio = 0.5\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2:\"EOS\", 3:\"UNK\"}\n",
    "        self.n_words = 4  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeEnString(s):\n",
    "#    s = unicodeToAscii(s.lower().strip())\n",
    "#    s = re.sub(r\"&apos;\", r\" \", s)\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "def normalizeChString(s):\n",
    "#    s = re.sub(r\"([。！？])\", r\" \\1\", s)\n",
    "#    s = re.sub(r\"[.-*]+\", r\" \", s)\n",
    "    return s.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It apos s very pretty and it has rapidly started to overgrow the once very rich biodiversity of the northwestern Mediterranean .'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizeEnString(\"It &apos;s very pretty , and it has rapidly started to overgrow the once very rich biodiversity of the northwestern Mediterranean .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, data='train'):\n",
    "    #data: train/dev/test\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    zh_lines = open('iwslt-zh-en/{}.tok.zh'.format(data)).read().split('\\n')\n",
    "    en_lines = open('iwslt-zh-en/{}.tok.en'.format(data)).read().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeChString(element[0]), normalizeEnString(element[1])] for element in zip(zh_lines, en_lines)]\n",
    "\n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "#    pairs = filterPairs(pairs)\n",
    "#    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 213378 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "ch 91144\n",
      "eng 59373\n",
      "Build vocabulary by top 85000 frequent word...\n",
      "ch 85004\n",
      "Build vocabulary by top 85000 frequent word...\n",
      "eng 59373\n",
      "['最 开始 我要 追溯到   我 还 在 俄亥俄州 巴伯 顿 的 欧克 代尔 学校 上 三年级 的 时候', 'I apos m going to start way back in the third grade at Oakdale School in Barberton Ohio .']\n"
     ]
    }
   ],
   "source": [
    "def build_topwordVocab(lang, vocab_size):\n",
    "    print(\"Build vocabulary by top {} frequent word...\".format(vocab_size))\n",
    "    sorted_word2Count = sorted(lang.word2count.items(),\n",
    "        key=operator.itemgetter(1),\n",
    "        reverse=True)\n",
    "    sorted_words = [x[0] for x in sorted_word2Count[:vocab_size]]\n",
    "    \n",
    "    lang.word2index = {}\n",
    "\n",
    "    for ind, word in enumerate(sorted_words):\n",
    "            lang.word2index[word] = ind + 4\n",
    "\n",
    "#     lang.word2index = {}\n",
    "    lang.index2word = {}\n",
    "    lang.index2word[0] = \"PAD\"\n",
    "    lang.index2word[1] = \"SOS\"\n",
    "    lang.index2word[2] = \"EOS\"\n",
    "    lang.index2word[3] = \"UNK\"\n",
    "\n",
    "    for ind, word in enumerate(sorted_words):\n",
    "        lang.index2word[ind + 4] = word\n",
    "    \n",
    "    lang.n_words = len(lang.index2word)\n",
    "    \n",
    "    print(lang.name, lang.n_words)\n",
    "    return lang\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('ch', 'eng')\n",
    "\n",
    "input_lang = build_topwordVocab(input_lang,vocab_size=85000)\n",
    "output_lang = build_topwordVocab(output_lang, vocab_size=85000)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85004"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    }
   ],
   "source": [
    "_, _, val_pairs = readLangs('ch', 'eng', 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pairs = val_pairs[:-1] # since last line is '',''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我 欣然同意 。', 'And I said quot Yes . quot ']\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(val_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input = [normalizeChString(line) for line in open('iwslt-zh-en/dev.tok.zh').read().split('\\n')]\n",
    "val_output = [normalizeEnString(line) for line in open('iwslt-zh-en/dev.tok.en').read().split('\\n')]\n",
    "val_inputs = []\n",
    "val_outputs = []\n",
    "for element in zip(val_input, val_output):\n",
    "    val_inputs.append(element[0])\n",
    "    val_outputs.append(element[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_word2Count = sorted(output_lang.word2count.items(),\n",
    "#     key=operator.itemgetter(1),\n",
    "#     reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_lang.word2index ###标点符号排第一 之后要改掉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    idxs = []\n",
    "    for word in sentence.split(' '):\n",
    "        try:\n",
    "            idxs.append(lang.word2index[word])\n",
    "        except KeyError:\n",
    "            idxs.append(3)  # 3 is the id of 'UNK'\n",
    "    idxs.append(EOS_token)\n",
    "    return idxs\n",
    "\n",
    "# def tensorFromSentence(lang, sentence):\n",
    "#     indexes = indexesFromSentence(lang, sentence)\n",
    "#     indexes.append(EOS_token)\n",
    "#     return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "# def tensorsFromPair(pair):\n",
    "#     input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "#     target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "#     return (input_tensor, target_tensor)\n",
    "\n",
    "class VocabDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "#         pairs = [tensorsFromPair(pair) for pair in pairs]\n",
    "#         self.source_sent_list = [i[0] for i in pairs]\n",
    "#         self.target_sent_list = [i[1] for i in pairs]\n",
    "        \n",
    "        self.source_sent_list = [indexesFromSentence(input_lang,pair[0]) for pair in pairs]\n",
    "        self.target_sent_list = [indexesFromSentence(output_lang,pair[1]) for pair in pairs]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.source_sent_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        token1_idx = self.source_sent_list[key][:MAX_LENGTH]\n",
    "        token2_idx = self.target_sent_list[key][:MAX_LENGTH]\n",
    "        return [token1_idx,token2_idx, len(token1_idx), len(token2_idx)]\n",
    "\n",
    "    \n",
    "def Vocab_collate_func(batch):\n",
    "    source_sent_list = []\n",
    "    target_sent_list = []\n",
    "    source_len_list = []\n",
    "    target_len_list = []\n",
    "\n",
    "    for datum in batch:   ### batch = sample\n",
    "        source_len_list.append(datum[2])\n",
    "        target_len_list.append(datum[3])\n",
    "\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        \n",
    "        # source sentence processing\n",
    "        padded_source = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_LENGTH-datum[2])),          ### 0代表左边没有pad,右边的值代表右边pad的个数\n",
    "                                mode=\"constant\", constant_values=PAD_token)\n",
    "        source_sent_list.append(padded_source)\n",
    "        \n",
    "        # target sentence processing\n",
    "        padded_target = np.pad(np.array(datum[1]), \n",
    "                                pad_width=((0,MAX_LENGTH-datum[3])),          ### 0代表左边没有pad,右边的值代表右边pad的个数\n",
    "                                mode=\"constant\", constant_values=PAD_token)\n",
    "        target_sent_list.append(padded_target)\n",
    "        \n",
    "    return [torch.tensor(source_sent_list,device = device), \n",
    "            torch.tensor(target_sent_list,device = device),\n",
    "            torch.LongTensor(source_len_list,device = device), \n",
    "            torch.LongTensor(target_len_list,device = device)]\n",
    "\n",
    "train_dataset = VocabDataset(pairs)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=Vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = VocabDataset(val_pairs)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        collate_fn=Vocab_collate_func,\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(inputs, outputs, len1, len2) in enumerate(train_loader):\n",
    "    a, b = outputs, len1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1594,  9489,  6646,  ...,     0,     0,     0],\n",
       "        [  542,  6291,     4,  ...,     0,     0,     0],\n",
       "        [   32,    20,   537,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [ 3787,    81, 57886,  ...,     0,     0,     0],\n",
       "        [   56,     6,    41,  ...,     0,     0,     0],\n",
       "        [ 2988,   439,  3670,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1594, 9489, 6646,  286,   61,    5,  565, 2454,   83, 4014,    7, 5938,\n",
       "         588,    9,   18,    6,  169,  200,  173,  588,  513,  421,   16,   62,\n",
       "           9, 9328,   16,   26,  215,   29,    6,   31, 4050,   28,  115, 2709,\n",
       "          10, 2035,    4,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True)\n",
    "#        self.linear = nn.Linear(2*hidden_size, hidden_size)\n",
    "    def forward(self, input, hidden, batch_size):\n",
    "        embedded = self.embedding(input).view(1, batch_size, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "#        output = self.linear(output)\n",
    "\n",
    "        output = output[:, :, :self.hidden_size] + output[:, : ,self.hidden_size:]\n",
    "        return output, hidden\n",
    "        #output: eq_len, batch, num_directions * hidden_size\n",
    "        #hidden: num_layers * num_directions, batch, hidden_size)\n",
    "        \n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(2, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0, n_layers=1,max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size, padding_idx=0)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs, batch_size):\n",
    "        embedded = self.embedding(input).view(1, batch_size, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "#         embedded: torch.Size([1, 32, 256])\n",
    "#         hidden: torch.Size([1, 32, 256])\n",
    "        \n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)   \n",
    "#         attn_weights:torch.Size([32, 100])\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1),\n",
    "                                 encoder_outputs.transpose(0,1))\n",
    "#         encoder_outputs: 100*32*256 attn_applied: 32*1*256\n",
    "        output = torch.cat((embedded[0], attn_applied.transpose(0,1)[0]), 1)\n",
    "\n",
    "        # output: 32*768\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        # output 1*32*256\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "#         output: torch.Size([32, 69126])\n",
    "#         hidden: torch.Size([1, 32, 256])\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just one sentence input, could be batchlized \n",
    "def train(input_tensor, target_tensor, input_lengths, target_lengths, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, criterion, clip=50.0, max_len=MAX_LENGTH, mask = None):\n",
    "    encoder_optimizer.zero_grad()  # zero out the accumulated gradient over mini-batch\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    batch_size = input_tensor.size(1)\n",
    "\n",
    "#     input_length = input_tensor.size(0) # length of source sentence\n",
    "#     target_length = target_tensor.size(0)\n",
    "\n",
    "\n",
    "#    encoder_outputs, encoder_hidden = encoder(input_tensor, input_lengths, 0)\n",
    "    encoder_hidden = encoder.initHidden(batch_size)\n",
    "    encoder_outputs = torch.zeros(max_len, batch_size, encoder.hidden_size, device=device) \n",
    " \n",
    "    # feed-forward layer resulting encoder outputs, ei refers to each word token in input sentence\n",
    "    for ei in range(max_len):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden, batch_size)  \n",
    "        encoder_outputs[ei] = encoder_output[0] \n",
    "\n",
    "    #encoder_outputs:  # max_len x batch_size x hidden_size\n",
    "    #hidden: n_layers * 2 x batch_size x hidden_size\n",
    "    loss = 0\n",
    "\n",
    "    \n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]*batch_size], device=device)  # decoder_input: torch.Size([1, 32])\n",
    "    # init decoder hidden \n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "    \n",
    "#    max_target_length = max(target_lengths)\n",
    "    all_decoder_outputs = Variable(torch.zeros(max_len, batch_size, decoder.output_size))\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(max_len):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs, batch_size)\n",
    "            \n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "#            temp_loss = criterion(decoder_output, target_tensor[di])\n",
    "#            loss += temp_loss * mask[di:di+1].float()  \n",
    "#            loss += temp_loss.float()\n",
    "#            ave_loss = loss.sum()/batch_size \n",
    "            \n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(max_len):\n",
    "            # decoder_input: torch.Size([1, 32])\n",
    "            # decoder_hidden: torch.Size([1, 32, 256]) 1 token * batch * hidden size\n",
    "            # encoder_outputs: torch.Size([100, 32, 512])\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs, batch_size)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            # topv: 32*1\n",
    "            # topi: 32*1\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            all_decoder_outputs[di] = decoder_output\n",
    "            # decoder_input: 32\n",
    "            # target_tensor: 100*32\n",
    "            # decoder_output: 32*69127 \n",
    "#            temp_loss = criterion(decoder_output, target_tensor[di])\n",
    "#            loss += temp_loss * mask[di:di+1].float()\n",
    "#            loss += temp_loss.float()\n",
    "            # loss size 1*32\n",
    "#            ave_loss = loss.sum()/batch_size  \n",
    "            \n",
    "    # Loss calculation and backpropagation\n",
    "\n",
    "    loss = masked_cross_entropy(\n",
    "        all_decoder_outputs.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        target_tensor.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        target_lengths\n",
    "    )\n",
    "    loss.backward()\n",
    "    #    ave_loss.backward()\n",
    "    \n",
    "    # Clip gradient norms\n",
    "    ec = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    dc = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "\n",
    "    \n",
    "    encoder_optimizer.step()   # update parameters\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=100, plot_every=100, learning_rate=0.005):\n",
    "    start = time.time()\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss(reduction='none') ##!!!!!!!!!!1 这个loss是否要换成crossentropy\n",
    "\n",
    "    for epoch in range(1, n_iters + 1):\n",
    "        plot_losses = []\n",
    "        print_loss_total = 0  # Reset every print_every\n",
    "        plot_loss_total = 0  # Reset every plot_every\n",
    "        for i, (input_sentences, target_sentences,len1,len2) in enumerate(train_loader): \n",
    "            input_tensor = input_sentences.transpose(0,1)   # 13*100 to 100*13\n",
    "            target_tensor = target_sentences.transpose(0,1)\n",
    "            mask = target_tensor.ge(1)   # 100 * 13\n",
    "            loss = train(input_tensor, target_tensor, len1, len2, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion, mask = mask)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if i > 0 and i % print_every == 0:\n",
    "                print_loss_avg = print_loss_total / print_every\n",
    "                print_loss_total = 0\n",
    "                bleu_score, (sys_sents, ref_sents) = test_model(encoder, decoder, val_loader)\n",
    "                print('Time: {}, Epoch: [{}/{}], Step: [{}/{}], Train Loss: {}, Validation Score: {} \\n Predicted sentence: {} \\n Reference sentence: {}'.format(\n",
    "                    timeSince(start, i + 1/len(train_loader)), epoch, n_iters, i, \n",
    "                    len(train_loader),print_loss_avg, bleu_score, sys_sents, ref_sents))\n",
    "\n",
    "            if i > 0 and i % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "        print(plot_losses)\n",
    "        showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_outputs(encoder, decoder, input_sentences, max_length=MAX_LENGTH): \n",
    "    with torch.no_grad():\n",
    "        input_tensor = input_sentences.transpose(0,1)   # 32*100 to 100*32\n",
    "        batch_size = input_tensor.size(1)\n",
    "        encoder_hidden = encoder.initHidden(batch_size)\n",
    "\n",
    "#        input_length = input_tensor.size(0) # length of source sentence\n",
    "        encoder_outputs = torch.zeros(max_length, batch_size, encoder.hidden_size, device=device) \n",
    "        \n",
    "        for ei in range(max_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], \n",
    "                                                     encoder_hidden, batch_size)  \n",
    "            encoder_outputs[ei] = encoder_output[0] \n",
    "            \n",
    "\n",
    "            \n",
    "        decoder_input = torch.tensor([[SOS_token]*batch_size], device=device)  # decoder_input: torch.Size([1, 32])\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        \n",
    "        decoded_words = np.empty((max_length, batch_size), dtype=object)\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs, batch_size)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "\n",
    "#            topi_lst = topi.squeeze().detach().tolist()\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            \n",
    "            decoded_words[di:] = np.array(['<EOS>' if idx==EOS_token else output_lang.index2word[idx] for idx in decoder_input.tolist()])\n",
    "        \n",
    "        return decoded_words.transpose()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(encoder, decoder, loader):\n",
    "    score = []\n",
    "    for i, (input_sentences, target_sentences, len1, len2) in enumerate(loader):\n",
    "        batch_size = input_sentences.size(0)\n",
    "#        print(batch_size)\n",
    "        sys_sentences = []\n",
    "        for sentence in get_batch_outputs(encoder, decoder, input_sentences):\n",
    "            try:\n",
    "                end_idx = sentence.tolist().index('<EOS>')\n",
    "                sys_sentences.append(' '.join(sentence[:end_idx]))\n",
    "            except ValueError:\n",
    "                sys_sentences.append(' '.join(sentence))\n",
    "#        sys_sentences = [' '.join(sentence) for sentence in get_batch_outputs(encoder, decoder, input_sentences)]\n",
    "        ref_sentences = [val_pair[1] for val_pair in val_pairs[i*batch_size:(i+1)*batch_size]]\n",
    "#        print(ref_sentences)\n",
    "        score_batch = [sacrebleu.corpus_bleu([sys],[[ref]]).score for sys, ref in zip(sys_sentences, ref_sentences)]\n",
    "        score.append(sum(score_batch)/len(score_batch))\n",
    "    idx = random.randint(0,min(len(sys_sentences),len(ref_sentences)))\n",
    "    return sum(score)/len(score), (sys_sentences[idx], ref_sentences[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1807314790419282,\n",
       " ('house Dunlop forging Berner solid rough expertise Starters Writing accounted thickening Dentistry Dentistry Dentistry Grasshopper Dentistry Dentistry Dentistry Dentistry looking teardrop expertise types chlamydia reenacted pulses Lithuania complex expertise Starters Writing Berner expertise solid Starters Writing accounted thickening thickening frequent wrecked Donaldson Miwa accounted thickening complex expertise types chlamydia reenacted pulses Lithuania complex expertise Starters Writing Berner expertise solid Starters Writing accounted thickening thickening frequent wrecked Donaldson Miwa accounted thickening complex expertise types chlamydia reenacted pulses Lithuania complex expertise Starters Writing Berner expertise solid Starters Writing accounted thickening thickening frequent wrecked Donaldson Miwa accounted thickening complex expertise types chlamydia reenacted',\n",
       "  'So I set it up in my home two years ago and since then we have never experienced any problem with lions .'))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "# attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0).to(device)\n",
    "\n",
    "# test_model(encoder1, attn_decoder1, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluateRandomly(encoder, decoder, n=10):\n",
    "#     for i in range(n):\n",
    "#         pair = random.choice(pairs)\n",
    "#         print('>', pair[0])\n",
    "#         print('=', pair[1])\n",
    "#         output_words = generate_output(encoder, decoder, pairs)\n",
    "#         output_sentence = ' '.join(output_words)\n",
    "#         print('<', output_sentence)\n",
    "#         print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING AND EVALUATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nansu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:93: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 11m 47s (- -12m 47s), Epoch: [1/3], Step: [20/6669], Train Loss: 1.673552219390869, Validation Score: 0.272699926481706 \n",
      " Predicted sentence: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      " Reference sentence: Thanks .\n"
     ]
    }
   ],
   "source": [
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 3, print_every=20, plot_every=1)\n",
    "\n",
    "torch.save(encoder1.state_dict(), \"saved_model/encoder_hiddenSize{}\".format(hidden_size))\n",
    "torch.save(attn_decoder1.state_dict(), \"saved_model/attn_decoder_hiddenSize{}\".format(hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
